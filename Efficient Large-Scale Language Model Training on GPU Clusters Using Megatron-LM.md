# Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM

论文时间23 Aug 2021

## 已有技术以及当前问题

### 数据并行

### 张量并行

张量（层内）模型并行技术，它通过在多个GPU上分割每个Transformer层内的矩阵乘法操作来克服这些限制。虽然这种方法适用于高达200亿参数的模型，但在更大的模型上会失效。

这带来了两个问题：一是张量并行所需的全规约通信需要通过服务器间的连接，其速度慢于多GPU服务器内部的高带宽NVLink；二是高度的模型并行会产生小型矩阵乘法操作，可能降低GPU利用率。

### 流水线模型并行

流水线模型并行是另一种技术，它将模型的层分布在多个GPU上，将批次分割成更小的微批次，并在这些微批次中进行流水线执行。

层的分配和前向/反向传播的调度策略会导致不同的性能权衡。无论采用何种调度，为保持严格的优化器语义，需要在设备间同步优化器步骤，导致每个批次结束时都需要清空流水线。根据注入流水线的微批次数量，可能会花费高达50%的时间来清空流水线。

流水线泡沫

### A100 gpu

### NVLink

### ZeRO ZeRO-3

### 分布式训练是通信密集型

### 自动探索并行策略的搜索空间

自动探索并行策略的搜索空间(如FlexFlow [22]， PipeDream [29]， Tarnawski等人[41]和DAPPLE[14])

### PipeMare, PipeDream, and PipeDream-2BW [23, 29 , 30 , 45 ]

### GPipe 

1F1B（默认的，交错的两种方式）

想到了有NFNB？但是这篇论文好像没有提及

### 8 InfiniBand networking cards 

### 激活重计算

### NCCL

### TeraPipe

### PipeTransformer

### HetPipe

### PipeMare

### DeepSpeed

### DeepSpeed

### Switch Transformers

## 摘要

### 贡献

将张量并行、流水线并行和数据并行组合起来，使其能够扩展到数千个GPU。提出了一种新的交错流水线调度（interleaved pipelining schedule）方法，可以在内存占用与现有方法相当的情况下提高10%以上的吞吐量。

## 介绍

### 当前研究遇到的问题

数据并行扩展通常效果不错，但有两个限制：一是超过一定点后，每个GPU的批处理大小变得太小，降低了GPU的利用率并增加了通信成本；二是可用于训练的加速器数量受到批处理大小的限制。

### 本文贡献

在这篇论文中，我们探讨了如何组合并行技术来最大化大型模型的训练吞吐量，同时保持严格的优化器语义。我们展示了如何结合流水线、张量和数据并行（我们称之为PTD-P）来训练大型语言模型，并在数千个GPU上实现良好的计算性能（达到峰值设备吞吐量的52%）

在3072个A100 GPU上几乎线性扩展，达到了每个GPU 163 teraFLOP/s的端到端训练吞吐量（包括通信、数据处理和优化），以及总计502 petaFLOP/s的聚合吞吐量，用于训练具有万亿参数的GPT模型，并使用混合精度。

与ZeRO进行了比较，发现我们的方法在具有175亿和5300亿参数的模型上比ZeRO-3为应对大型模型训练中的挑战，提出了多种模型并行技术。

## 并行方式

### 权重更新保持一致

为了严格保持优化器的语义，引入了周期性的流水线清空

## 并行化配置的性能分析（PERFORMANCE ANALYSIS OF PARALLELIZATION CONFIGURATIONS）

将流水线并行、张量模型并行与数据并行相结合进行模型训练时的性能影响。在固定GPU数量和批量大小的条件下，可以使用不同程度的并行方式来训练模型，每种维度都涉及到内存占用、设备利用率和通信量之间的权衡。

几种参数的选择

- **并行化维度**：用 (𝑝, 𝑡, 𝑑) 表示，其中 𝑝 是流水线模型并行大小，𝑡 是张量模型并行大小，𝑑 是数据并行大小。
- **GPU数量**：用 𝑛 表示，需要满足 𝑝 · 𝑡 · 𝑑 = 𝑛。
- **全局批量大小**：用 𝐵 表示，是输入的全局批次大小。
- **微批量大小**：用 𝑏 表示。
- **每个流水线中的微批次数**：用 𝑚 = 𝐵/(𝑏 · 𝑑) 表示

不同GPU之间的通信量如何受到流水线并行（𝑝）和张量模型并行（𝑡）的影响

激活重计算技术

## 实现

在使用流水线并行时对通信的优化

NCCL

InfiniBand

NVLink

计算方面，实施了三种针对模型的优化，包括改变Transformer层的数据布局以避免内存密集型的转置操作，使用PyTorch JIT生成融合内核，以及创建自定义内核以实现尺度、掩码和softmax操作的融合。

## 相关工作

1. **流水线并行的不同方式**：文章讨论了流水线并行的几种方式，如TeraPipe、PipeTransformer、HetPipe等，它们各自有不同的特点和优势。一些方法，如PipeDream-2BW和PipeMare，使用了松散的并行语义以提高吞吐量，但可能会牺牲收敛速度或最终精度。
2. **并行化组合的性能**：文章比较了仅使用流水线并行、数据并行和张量并行的性能。PTD-P组合了这些技术，以减少跨设备通信，同时利用高性能硬件如A100 GPU和高带宽链接。
3. **分片数据并行**：ZeRO方法将优化器状态和梯度分片在数据并行工作节点上，减少了内存占用，提高了效率。
4. **自动分区**：FlexFlow、PipeDream、DAPPLE等工具提供了模型训练图的自动分区，帮助优化跨多个设备的训练。
5. **高性能计算在模型训练中的应用**：Goyal等人和You等人展示了如何使用高性能计算技术快速训练高精度的图像分类模型，但这些模型通常不需要模型并行，因为它们能够适配在单个加速器上。


这段话提到了多种大模型训练中使用的并行化技术：

1. **TeraPipe**：针对自回归模型（如GPT），实现了单个训练序列中跨token的细粒度流水线并行。
2. **PipeTransformer**：通过冻结“稳定”权重的层，并专注于训练剩余的“活跃”层，弹性地调整流水线和数据并行的程度。
3. **HetPipe**：在异构加速器集上结合流水线和数据并行。
4. **PipeDream-2BW** 和 **PipeMare**：实现了放松语义的流水线并行，维护两个权重版本，无需昂贵的刷新操作即可保证1-stale权重更新。
5. **DeepSpeed**：结合流水线并行、张量并行和数据并行来训练高达万亿参数的模型。
6. **Mesh-TensorFlow**：提出了一种语言，用于轻松指定结合数据和模型并行的并行化策略。
7. **Switch Transformers**：使用Mesh-TensorFlow训练了一个拥有1.6万亿参数的稀疏激活专家模型。
8. **ZeRO** 和 **ZeRO-Infinity**：分片数据并行，其中优化器状态在数据并行工作者之间分片。
9. **FlexFlow**、**PipeDream**、**DAPPLE**、**Tarnawski** 等：自动在多个设备上分区模型训练图。
10. **Goyal** 和 **You** 等人的工作：展示了使用高性能计算技术来快速训练高精度的ImageNet模型。